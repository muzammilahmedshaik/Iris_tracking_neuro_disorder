{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7867,"status":"ok","timestamp":1661082109778,"user":{"displayName":"Shaik Muzammil","userId":"03578890591523390720"},"user_tz":300},"id":"w5fpA1_sjhFE","outputId":"dfc23cc4-22ea-4e3c-89f4-a7afd44217a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[K     |████████████████████████████████| 32.9 MB 59.3 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.2.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10.1\n"]}],"source":["pip install mediapipe"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1s-88Ln39XwHrVPZKsIneWMIYRCcFz6YI"},"id":"AgCCfYN9Q2XK","outputId":"de444fbd-0876-4c0e-dd2a-7b625d808cdc","executionInfo":{"status":"ok","timestamp":1661082400560,"user_tz":300,"elapsed":197265,"user":{"displayName":"Shaik Muzammil","userId":"03578890591523390720"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from google.colab.patches import cv2_imshow\n","import cv2 as cv\n","import mediapipe as mp\n","import time\n","import math\n","import numpy as np\n","# variables \n","frame_counter =0\n","CEF_COUNTER =0\n","TOTAL_BLINKS =0\n","# constants\n","CLOSED_EYES_FRAME =3\n","FONTS =cv.FONT_HERSHEY_COMPLEX\n","\n","# face bounder indices \n","FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n","\n","# lips indices for Landmarks\n","LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n","LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n","UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n","# Left eyes indices \n","LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n","LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n","\n","# right eyes indices\n","RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n","RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]\n","\n","# iris positions\n","RIGHT_IRIS = [474, 475, 476, 477]\n","\n","LEFT_IRIS = [469, 470, 471, 472]\n","L_H_LEFT = [33]  # right eye right most landmark\n","L_H_RIGHT = [133]  # right eye left most landmark\n","R_H_LEFT = [362]  # left eye right most landmark\n","R_H_RIGHT = [263]  # left eye left most landmark\n","\n","map_face_mesh = mp.solutions.face_mesh\n","# camera object \n","camera = cv.VideoCapture(\"/content/asu_jeff.webm\")\n","# landmark detection function \n","def landmarksDetection(img, results, draw=False):\n","    img_height, img_width= img.shape[:2]\n","    # list[(x,y), (x,y)....]\n","    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n","    if draw :\n","        [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n","\n","    # returning the list of tuples for each landmarks \n","    return mesh_coord\n","\n","# Euclaidean distance to calculate distance between cords\n","def euclaideanDistance(point, point1):\n","    x, y = point.ravel()\n","    x1, y1 = point1.ravel()\n","    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n","    return distance\n","\n","# Blinking Ratio of horizontal and vertical vertex\n","def iris_position(iris_center, left_point, right_point):\n","    center_to_right_position =  euclaideanDistance(iris_center, right_point)\n","    total_distance =  euclaideanDistance(right_point, left_point)\n","    ratio = center_to_right_position / total_distance\n","    iris_position = \"\"\n","    if ratio >= 0.65:\n","         iris_poistion=\"right\"\n","    elif ratio >= 0.50 and ratio <= 0.55:\n","         iris_position=\"center\"\n","    elif ratio >= 0.29 and ratio <= 0.39:\n","         iris_position=\"left\"\n","    elif ratio >= 0.56 and ratio <= 0.64:\n","         iris_position = \"up\"\n","    elif ratio >= 0.40 and ratio <=0.49:\n","         iris_position = \"down\"\n","    else:\n","         iris_position = \"center\"\n","\n","    return iris_position, ratio\n","\n","with map_face_mesh.FaceMesh(min_detection_confidence =0.5, min_tracking_confidence=0.5, refine_landmarks=True, max_num_faces = 1) as face_mesh:\n","\n","    # starting time here \n","    start_time = time.time()\n","    # starting Video loop here.\n","    while True:\n","        frame_counter +=1 # frame counter\n","        ret, frame = camera.read() # getting frame from camera \n","        if not ret: \n","            break # no more frames break\n","        #  resizing frame\n","        \n","        frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n","        img_h, img_w= frame.shape[:2]\n","        rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n","        results  = face_mesh.process(rgb_frame)\n","        if results.multi_face_landmarks:\n","            mesh_points = np.array(\n","                [\n","                    np.multiply([p.x, p.y],[img_w, img_h]).astype(int)\n","                    for p in results.multi_face_landmarks[0].landmark\n","                ]\n","            )\n","            (l_cx, l_cy), l_radius = cv.minEnclosingCircle(mesh_points[LEFT_IRIS])\n","            (r_cx, r_cy), r_radius = cv.minEnclosingCircle(mesh_points[RIGHT_IRIS])\n","            center_left = np.array([l_cx, l_cy], dtype=np.int32)\n","            center_right = np.array([r_cx, r_cy], dtype=np.int32)\n","            frame = cv.resize(frame, (480, 360))\n","            # cv.circle(frame,center_right,int(r_radius),(255,0,255),1,cv.LINE_AA)\n","            # cv.circle(frame,center_left,int(l_radius),(255,0,255),1,cv.LINE_AA)\n","            # cv.circle(frame,mesh_points[R_H_LEFT][0],3,(255,0,255),-1,cv.LINE_AA)\n","            # cv.circle(frame,mesh_points[R_H_RIGHT][0],3,(255,0,255),-1,cv.LINE_AA)\n","            iris_pos, ratio = iris_position(center_right, mesh_points[R_H_RIGHT], mesh_points[R_H_LEFT][0])\n","\n","            # cv.putText(frame, f'ratio {ratio}', (100, 100), FONTS, 1.0, utils.GREEN, 2)\n","            #utils.colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, utils.PINK, utils.YELLOW)\n","\n","\n","            cv.putText(frame, f'Iris Position: {iris_pos} {ratio:.2f}', (100, 50), cv.FONT_HERSHEY_PLAIN, 1.2, (0,255,0), 1, cv.LINE_AA)\n","            cv2_imshow(frame)\n","            \n","            #utils.colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n","            \n","            #cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n","            #cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n","\n","\n","\n","        # calculating  frame per seconds FPS\n","        end_time = time.time()-start_time\n","        fps = frame_counter/end_time\n","\n","        #frame =utils.textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n","        # writing image for thumbnail drawing shape\n","        frame = cv.resize(frame, (480, 360))\n","        # cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n","        # cv2_imshow(frame)\n","        \n","        key = cv.waitKey(2)\n","        if key==ord('q') or key ==ord('Q'):\n","            break\n","    cv.destroyAllWindows()\n","    camera.release()"]}],"metadata":{"colab":{"name":"Iris_tracking.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNafCwoxDWn3C3c0Ml0+dKl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}